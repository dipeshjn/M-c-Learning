{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = load_digits()\n",
    "x=digit.data\n",
    "y=digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797L, 64L), (1797L,))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC(C=1.1,kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        60\n",
      "          1       0.93      1.00      0.96        52\n",
      "          2       1.00      1.00      1.00        56\n",
      "          3       1.00      0.96      0.98        56\n",
      "          4       1.00      1.00      1.00        52\n",
      "          5       1.00      1.00      1.00        56\n",
      "          6       1.00      1.00      1.00        58\n",
      "          7       1.00      1.00      1.00        55\n",
      "          8       0.98      0.91      0.94        44\n",
      "          9       0.98      1.00      0.99        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.88888888888889"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,pred1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 54  0  0  0  0  1  1]\n",
      " [ 0  0  0  0 52  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 56  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 58  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  4  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 51]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test,pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVC(C=1.1,kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        60\n",
      "          1       0.98      1.00      0.99        52\n",
      "          2       1.00      1.00      1.00        56\n",
      "          3       1.00      0.98      0.99        56\n",
      "          4       1.00      1.00      1.00        52\n",
      "          5       1.00      1.00      1.00        56\n",
      "          6       1.00      0.98      0.99        58\n",
      "          7       1.00      1.00      1.00        55\n",
      "          8       0.96      0.98      0.97        44\n",
      "          9       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.44444444444444"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,pred2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 52  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 56  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 57  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 43  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 51]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SVC(C=1.1,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.45      0.62        60\n",
      "          1       1.00      0.31      0.47        52\n",
      "          2       1.00      0.25      0.40        56\n",
      "          3       1.00      0.41      0.58        56\n",
      "          4       1.00      0.60      0.75        52\n",
      "          5       1.00      0.45      0.62        56\n",
      "          6       1.00      0.43      0.60        58\n",
      "          7       1.00      0.49      0.66        55\n",
      "          8       0.14      1.00      0.24        44\n",
      "          9       1.00      0.55      0.71        51\n",
      "\n",
      "avg / total       0.93      0.48      0.57       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.148148148148145"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,pred3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0  0  0 33  0]\n",
      " [ 0 16  0  0  0  0  0  0 36  0]\n",
      " [ 0  0 14  0  0  0  0  0 42  0]\n",
      " [ 0  0  0 23  0  0  0  0 33  0]\n",
      " [ 0  0  0  0 31  0  0  0 21  0]\n",
      " [ 0  0  0  0  0 25  0  0 31  0]\n",
      " [ 0  0  0  0  0  0 25  0 33  0]\n",
      " [ 0  0  0  0  0  0  0 27 28  0]\n",
      " [ 0  0  0  0  0  0  0  0 44  0]\n",
      " [ 0  0  0  0  0  0  0  0 23 28]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test,pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = SVC(C=1.1,kernel = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        60\n",
      "          1       0.10      1.00      0.19        52\n",
      "          2       0.00      0.00      0.00        56\n",
      "          3       0.00      0.00      0.00        56\n",
      "          4       0.00      0.00      0.00        52\n",
      "          5       0.00      0.00      0.00        56\n",
      "          6       0.00      0.00      0.00        58\n",
      "          7       0.00      0.00      0.00        55\n",
      "          8       0.00      0.00      0.00        44\n",
      "          9       0.00      0.00      0.00        51\n",
      "\n",
      "avg / total       0.01      0.10      0.02       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.62962962962963"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,pred4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 37  0  0  0  0  0  0 23  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0 55  0  0  0  0  0  0  1  0]\n",
      " [ 0 56  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  0  0  9  0]\n",
      " [ 0 57  0  0  0  0  0  0  1  0]\n",
      " [ 0 54  0  0  0  0  0  0  1  0]\n",
      " [ 0 44  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test,pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
